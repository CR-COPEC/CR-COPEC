{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CR-COPEC/CR-COPEC/blob/main/CR_COPEC_Tensorflow_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec93x_WzJGf",
        "outputId": "156532ae-39e5-423c-d3de-e7e1a07c0c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device_count: 1\n",
            "device 0 capability (7, 5)\n",
            "device 0 name Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Check device\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_count = torch.cuda.device_count()\n",
        "    print(\"device_count: {}\".format(device_count))\n",
        "    for device_num in range(device_count):\n",
        "        print(\"device {} capability {}\".format(\n",
        "            device_num,\n",
        "              torch.cuda.get_device_capability(device_num)))\n",
        "        print(\"device {} name {}\".format(device_num, torch.cuda.get_device_name(device_num)))\n",
        "else:\n",
        "    print(\"no cuda device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoxJhyQCuYFZ",
        "outputId": "8b1eec20-bfa9-49aa-deb0-f72c1d173f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/MyDrive/Colab Notebooks/CR-COPEC\n"
          ]
        }
      ],
      "source": [
        "# Mounting google drive\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "%cd gdrive/MyDrive/Colab\\ Notebooks/CR-COPEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1sZdECVDzd4b"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install tensorflow_text==2.8.1\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dNLQCvngzapS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bdbfb88f-affa-4dd4-8494-bf082867c23a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "seed_value= 0\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predefine hyperparameters and model-type\n",
        "model_name='bert_base'\n",
        "current_lr= 2e-6\n",
        "epoch=1\n",
        "batch=32"
      ],
      "metadata": {
        "id": "UYialah1ZxzP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LKBS9yZux02"
      },
      "source": [
        " ## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRIvv-Xbu0BX",
        "outputId": "096201b9-e520-4642-873d-fe3a93817f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-de2df54479ee>:2: DtypeWarning: Columns (1,3,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(\"data/cr-copec_total_train_.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 228,879\n",
            "\n",
            "Number of valid sentences: 25,431\n",
            "\n",
            "Number of test sentences: 29,176\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "train_df = pd.read_csv(\"data/cr-copec_total_train.csv\")\n",
        "val_df = pd.read_csv(\"data/cr-copec_total_val.csv\")\n",
        "test_df = pd.read_csv(\"data/cr-copec_total_test.csv\")\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))\n",
        "print('Number of valid sentences: {:,}\\n'.format(val_df.shape[0]))\n",
        "print('Number of test sentences: {:,}\\n'.format(test_df.shape[0]))\n",
        "\n",
        "# Display 5 rows from the data.\n",
        "# train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I-RWmEFQxnPM"
      },
      "outputs": [],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "train_texts, train_labels = train_df.sentence.values.tolist(), [1 if i=='yes' else 0 for i in train_df.true_label.values]\n",
        "val_texts, val_labels = val_df.sentence.values.tolist(), [1 if i=='yes' else 0 for i in val_df.true_label.values]\n",
        "test_texts, test_labels = test_df.sentence.values.tolist(), [1 if i=='yes' else 0 for i in test_df.true_label.values]\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_texts,train_labels)).shuffle(len(train_texts), seed=seed_value).batch(batch)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_texts,val_labels)).shuffle(len(val_texts), seed=seed_value).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eTbA-DHxnTy"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AWlgYVcbfCJ0"
      },
      "outputs": [],
      "source": [
        "if model_name == 'bert_base':\n",
        "  model_path ='https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
        "  model_preprocess ='https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "elif model_name == 'electra_base':\n",
        "  model_path = 'https://tfhub.dev/google/electra_base/2'\n",
        "  model_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "tfhub_handle_encoder = model_path\n",
        "tfhub_handle_preprocess = model_preprocess\n",
        "\n",
        "def build_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, dtype=tf.float64, trainable=True, name=model_name+'_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.3, seed=seed_value)(net)\n",
        "    net = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed_value), activation='sigmoid', name='classifier')(net)\n",
        "    model=tf.keras.Model(text_input, net)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=current_lr),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                            metrics=tf.metrics.BinaryAccuracy())\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "GpDkpNpqPX85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CGfSdlq6xuuT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def namefile(model_name):\n",
        "    filepath= \"#models/tensorflow_\"+model_name+\".hdf5\"\n",
        "    return filepath\n",
        "\n",
        "for fold in range(1):\n",
        "    tf.keras.utils.set_random_seed(seed_value)\n",
        "    os.environ[\"TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS\"]=\"True\"\n",
        "\n",
        "\n",
        "    model = build_model()\n",
        "    filepath= namefile(model_name)\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    print(f'Training model with {tfhub_handle_encoder}')\n",
        "    history = model.fit(x=train_ds,\n",
        "                                    validation_data=val_ds,\n",
        "                                    epochs=epoch,\n",
        "                                    callbacks=callbacks_list,\n",
        "                                    shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "x5Rquht5RnlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(file):\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, dtype=tf.float64, trainable=True, name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.3, seed=seed_value)(net)\n",
        "    net = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed_value), activation='sigmoid', name='classifier')(net)\n",
        "    model=tf.keras.Model(text_input, net)\n",
        "    model.load_weights(file)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=current_lr),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                             metrics=tf.metrics.BinaryAccuracy())\n",
        "    return model"
      ],
      "metadata": {
        "id": "yQgUtyQuRqg-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath= namefile(model_name)\n",
        "model = load_model(filepath)\n",
        "\n",
        "text_sample1=['The decline in Consumer Product Segment gross profit margin is mainly attributable to increased levels of royalty cost resulting from changes in the sales mix towards the higher royalties associated with licensed characters products, and a deterioration in the gross profit margins at Penn which decreased to 12.0% from 22.1%.']\n",
        "text_sample2=['The increase in unit shipments and average selling price reflects the OEMs continued move to finished luggage compartments.']\n",
        "\n",
        "print(model.predict(text_sample1))\n",
        "print(model.predict(text_sample2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXQEtVEHSXf_",
        "outputId": "0807e922-6813-4e30-c9d3-1d05d41193c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9809161]]\n",
            "[[0.11681046]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM86cQaCHFnbxs+biwiTGsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}